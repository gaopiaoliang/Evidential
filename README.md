# Credible Remote Sensing Scene Classification Using Evidential Fusion on Aerial-Ground Dual-view Images([arXiv](https://arxiv.org/abs/2301.00622))

# Introduction 
1. A Theory of Evidence Based Sample Uncertainty Quantification (TEB-SUQ) approach is used in both views of aerial and ground images to measure the decision risk during their fusion.
2. An Evidential Fusion strategy is proposed to fuse aerial-ground dual-view images in decision-level for remote sensing scene classification. Unlike other existing
decision-level fusion networks, the proposed strategy focuses the results not only on the classification probability but also on the decision risk of each perspective. As a result, the final result will depend more on the view with lower decision risk.
3. A more concise loss function, namely Reciprocal Loss is designed to simultaneously constrain the uncertainty of individual view and the uncertainty of their fusion. It
can be used not only to train an end-to-end aerial-ground dual-view remote sensing scene classification model, but also to train a fusion classifier without feature extraction.
# Dataset 
[Download the Datasets](http://www.patreo.dcc.ufmg.br/multi-view-datasets/)
# citation:
If you find our work is useful, please kindly cite the following:
BibTex
```
@misc{https://doi.org/10.48550/arxiv.2301.00622,
  doi = {10.48550/ARXIV.2301.00622},
  
  url = {https://arxiv.org/abs/2301.00622},
  
  author = {Zhao, Kun and Gao, Qian and Hao, Siyuan and Sun, Jie and Zhou, Lijian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Credible Remote Sensing Scene Classification Using Evidential Fusion on Aerial-Ground Dual-view Images},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

```
